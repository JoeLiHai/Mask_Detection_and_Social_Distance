{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bird_distance (1).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"947619ba3e9642a289092a3f8f417d21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0f99d49c07cd4c84b29ca4afdc59dd09","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1eb1879a1f5b451394909da7c18f2272","IPY_MODEL_c3893d230ba14e31a123c322495bc1eb"]}},"0f99d49c07cd4c84b29ca4afdc59dd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1eb1879a1f5b451394909da7c18f2272":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a64b441fafea4c318b02e1dffbe57340","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":349,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":349,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f67a8064abdb4a3ca2ae04381dc91f65"}},"c3893d230ba14e31a123c322495bc1eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_365f652352044a21b9a00b54ff03bd5a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 349/349 [00:33&lt;00:00, 10.36it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37bebf65b1a943e2a0ff361925b1af5f"}},"a64b441fafea4c318b02e1dffbe57340":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f67a8064abdb4a3ca2ae04381dc91f65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"365f652352044a21b9a00b54ff03bd5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37bebf65b1a943e2a0ff361925b1af5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"V9IUW67sqQiT"},"source":["from base64 import b64encode\n","from google.colab import files\n","from google.colab.patches import cv2_imshow\n","from IPython.display import HTML\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","import cv2\n","import numpy as np\n","import os\n","import torch\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8fDxYSGUHXB","executionInfo":{"status":"ok","timestamp":1626321159885,"user_tz":-480,"elapsed":16367,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"}},"outputId":"5baf10ed-c25d-4432-a8d5-75e2e4fa93f3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25evnqY7qcnW","executionInfo":{"elapsed":30789,"status":"ok","timestamp":1626156566246,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"},"user_tz":-480},"outputId":"1008a33d-3292-4cf8-b59d-aa492dba49cf"},"source":["# It may take a while...\n","!wget \"https://documents.epfl.ch/groups/c/cv/cvlab-pom-video1/www/campus4-c0.avi\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-07-13 06:08:54--  https://documents.epfl.ch/groups/c/cv/cvlab-pom-video1/www/campus4-c0.avi\n","Resolving documents.epfl.ch (documents.epfl.ch)... 128.178.222.197, 2001:620:618:1de:1:80b2:dec5:1\n","Connecting to documents.epfl.ch (documents.epfl.ch)|128.178.222.197|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 33448124 (32M) [application/octet-stream]\n","Saving to: ‚Äòcampus4-c0.avi‚Äô\n","\n","campus4-c0.avi      100%[===================>]  31.90M  1.14MB/s    in 30s     \n","\n","2021-07-13 06:09:25 (1.06 MB/s) - ‚Äòcampus4-c0.avi‚Äô saved [33448124/33448124]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjy-nLuuUSjn","executionInfo":{"status":"ok","timestamp":1626321186827,"user_tz":-480,"elapsed":21614,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"}},"outputId":"1ffa433c-a218-4194-d723-e0edf81563dd"},"source":["model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/YOLOv5/face-mask/best0708_3.pt',force_reload=True) #force_reload ‰∏çÁü•ÈÅìÊúâ‰ΩïÁî®"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n"],"name":"stdout"},{"output_type":"stream","text":["YOLOv5 üöÄ 2021-7-15 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Collecting PyYAML>=5.3.1\n","  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","Installing collected packages: PyYAML\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.4.1\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Fusing layers... \n","Model Summary: 484 layers, 88404072 parameters, 0 gradients\n","Adding AutoShape... \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7BiGIJpVacQ","executionInfo":{"elapsed":1029,"status":"ok","timestamp":1625281654803,"user":{"displayName":"ÂçØÁ±≥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih-bcgIIbuEJcoVDPRD6S8wMqOpbKwEb5Ozt5DOw=s64","userId":"08071178439141397145"},"user_tz":-480},"outputId":"89cde03a-77d0-4672-c6c4-b314c1b9071b"},"source":["img = '/content/drive/MyDrive/YOLOv5/Person/2.jpg'\n","model.conf = 0.1\n","results = model(img)\n","results.print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["image 1/1: 855x1140 6 no_masks, 26 with_masks, 31 persons\n","Speed: 388.3ms pre-process, 160.2ms inference, 91.3ms NMS per image at shape (1, 3, 480, 640)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_UADNrFVhlN","executionInfo":{"elapsed":282,"status":"ok","timestamp":1625281667410,"user":{"displayName":"ÂçØÁ±≥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih-bcgIIbuEJcoVDPRD6S8wMqOpbKwEb5Ozt5DOw=s64","userId":"08071178439141397145"},"user_tz":-480},"outputId":"9bf99e22-01c0-43ac-8dac-c3e90e57b77f"},"source":["results.save()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved 2.jpg to runs/hub/exp\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"fun3NT4-XDx7","executionInfo":{"elapsed":298,"status":"ok","timestamp":1625282069345,"user":{"displayName":"ÂçØÁ±≥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih-bcgIIbuEJcoVDPRD6S8wMqOpbKwEb5Ozt5DOw=s64","userId":"08071178439141397145"},"user_tz":-480},"outputId":"6c9951c9-da6a-49f7-d61d-245ebd4ab9dc"},"source":["results.pandas().xyxy[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","      <th>confidence</th>\n","      <th>class</th>\n","      <th>name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>847.875000</td>\n","      <td>164.097656</td>\n","      <td>1091.906250</td>\n","      <td>810.468750</td>\n","      <td>0.951660</td>\n","      <td>2</td>\n","      <td>person</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>749.906250</td>\n","      <td>98.135742</td>\n","      <td>891.515625</td>\n","      <td>317.730469</td>\n","      <td>0.937500</td>\n","      <td>2</td>\n","      <td>person</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>168.328125</td>\n","      <td>216.978516</td>\n","      <td>236.906250</td>\n","      <td>290.566406</td>\n","      <td>0.930176</td>\n","      <td>1</td>\n","      <td>with_mask</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>590.039062</td>\n","      <td>281.214844</td>\n","      <td>651.492188</td>\n","      <td>345.339844</td>\n","      <td>0.925293</td>\n","      <td>1</td>\n","      <td>with_mask</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>440.859375</td>\n","      <td>159.199219</td>\n","      <td>500.531250</td>\n","      <td>220.875000</td>\n","      <td>0.921387</td>\n","      <td>1</td>\n","      <td>with_mask</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>233.566406</td>\n","      <td>111.161133</td>\n","      <td>298.136719</td>\n","      <td>221.097656</td>\n","      <td>0.148682</td>\n","      <td>0</td>\n","      <td>no_mask</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>295.019531</td>\n","      <td>49.875000</td>\n","      <td>388.089844</td>\n","      <td>199.722656</td>\n","      <td>0.139526</td>\n","      <td>0</td>\n","      <td>no_mask</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>2.031738</td>\n","      <td>43.417969</td>\n","      <td>110.771484</td>\n","      <td>804.234375</td>\n","      <td>0.138184</td>\n","      <td>2</td>\n","      <td>person</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>539.718750</td>\n","      <td>130.031250</td>\n","      <td>616.312500</td>\n","      <td>256.945312</td>\n","      <td>0.134888</td>\n","      <td>1</td>\n","      <td>with_mask</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>424.382812</td>\n","      <td>132.257812</td>\n","      <td>506.320312</td>\n","      <td>256.054688</td>\n","      <td>0.111572</td>\n","      <td>2</td>\n","      <td>person</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>63 rows √ó 7 columns</p>\n","</div>"],"text/plain":["          xmin        ymin         xmax        ymax  confidence  class  \\\n","0   847.875000  164.097656  1091.906250  810.468750    0.951660      2   \n","1   749.906250   98.135742   891.515625  317.730469    0.937500      2   \n","2   168.328125  216.978516   236.906250  290.566406    0.930176      1   \n","3   590.039062  281.214844   651.492188  345.339844    0.925293      1   \n","4   440.859375  159.199219   500.531250  220.875000    0.921387      1   \n","..         ...         ...          ...         ...         ...    ...   \n","58  233.566406  111.161133   298.136719  221.097656    0.148682      0   \n","59  295.019531   49.875000   388.089844  199.722656    0.139526      0   \n","60    2.031738   43.417969   110.771484  804.234375    0.138184      2   \n","61  539.718750  130.031250   616.312500  256.945312    0.134888      1   \n","62  424.382812  132.257812   506.320312  256.054688    0.111572      2   \n","\n","         name  \n","0      person  \n","1      person  \n","2   with_mask  \n","3   with_mask  \n","4   with_mask  \n","..        ...  \n","58    no_mask  \n","59    no_mask  \n","60     person  \n","61  with_mask  \n","62     person  \n","\n","[63 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPhK-1HQVoxE","executionInfo":{"elapsed":258,"status":"ok","timestamp":1625723149303,"user":{"displayName":"ÂçØÁ±≥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih-bcgIIbuEJcoVDPRD6S8wMqOpbKwEb5Ozt5DOw=s64","userId":"08071178439141397145"},"user_tz":-480},"outputId":"a20238f2-4be9-401e-a7ba-d61ddeedb0b5"},"source":["model.names"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['no_mask', 'mask', 'person']"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"MLZsabZutDq5"},"source":["# Load model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5x',\n","                       pretrained=True, verbose=False) #Âä†ËºâÈ†êË®ìÁ∑¥ÁöÑ YOLOv5s Ê®°Âûã\n","                       #verbose Default is True. # Â¶ÇÊûúÁÇ∫ FalseÔºåÂâáÂøΩÁï•ÊúâÈóúÂëΩ‰∏≠Êú¨Âú∞Á∑©Â≠òÁöÑÊ∂àÊÅØ\n","#model.cuda('cuda:0'); #?? #Â§ßÊ¶ÇÂè™ÊòØÈ°ØÁ§∫GPU Ê≤íÊúâÂøÖË¶ÅÂü∑Ë°å #ÁúüÁöÑÊ≤íÊÑèÁæ©"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ng00nSiqcqa"},"source":["def display_video(path): #ÊúâÁ©∫ÂÜç‰æÜÁ†îÁ©∂\n","    '''Display video in Colab.'''\n","    compressed_path = path.split('.')[0] #split ÂàáÁâá\n","    compressed_path = 'compressed_' + compressed_path + '.mp4'\n","\n","    if os.path.exists(compressed_path):\n","        os.remove(compressed_path)\n","\n","    # Convert video\n","    os.system(f\"ffmpeg -i {path} -vcodec libx264 {compressed_path}\")\n","\n","    # Show video\n","    mp4 = open(compressed_path,'rb').read()\n","    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","    return HTML(\"\"\"\n","    <video width=400 controls>\n","        <source src=\"%s\" type=\"video/mp4\">\n","    </video>\n","    \"\"\" % data_url)\n","    #print(HTML)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnB-vAwyqcuL"},"source":["filename = '/content/drive/MyDrive/YOLOv5/Person/087.mp4' #/content/drive/MyDrive/YOLOv5/Person/087.mp4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKv4dU96qcxk"},"source":["def calculate_distance(point1, point2):\n","    '''Calculate usual distance.'''\n","    x1, y1 = point1 #this is x1, y1 :(-24.606413, 559.09985)\n","    x2, y2 = point2\n","    return np.linalg.norm([x1 - x2, y1 - y2]) #‰ΩøÁî®Numpy Ê®°ÁµÑÊü•Ë©¢ÂÖ©Èªû‰πãÈñìÁöÑÊ≠êÂπæÈáåÂæóË∑ùÈõ¢ "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOg43X-Wqc0y"},"source":["def convert_to_bird(centers, M):\n","    '''Apply the perpective to the bird's-eye view.'''\n","    centers = [cv2.perspectiveTransform(np.float32([[center]]), M) for center in centers.copy()]\n","     #this is centers: [array([[[     149.59,      886.42]]], dtype=float32)] #shape =>1 1 2\n","    centers = [list(center[0, 0]) for center in centers.copy()]  #list(center[0,0]) tupleËΩâÁÇ∫list  #[[149.59, 886.42]] #ÊääcenterÂèñÂá∫‰æÜ\n","    return centers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2WMEzL1obzDp"},"source":["def img_text(img,border_size,person,lineCount, maskCount, nomaskCount):\n","    ratio = nomaskCount/(maskCount+nomaskCount+0.000001) #ÈÅøÂÖçÂàÜÊØçÁÇ∫0\n","    ratio = round(ratio,3)*100\n","    ratio = round(ratio,2)\n","    #print(f\"np isnan ? : {np.isnan(ratio)}\")\n","    border_text_color=[255,255,255]\n","    #Êî∂ÈõÜË≥áÊñô\n","\n","    \n","    text=\"social distance status:  \"\n","    cv2.putText(img ,text , (0, int(border_size-10)), cv2.FONT_HERSHEY_SIMPLEX,0.8,border_text_color, 2)  \n","    if lineCount >=3: #Ê¢ù‰ª∂ÂæÖÊîπËâØ ÔºåtextÊì∫Êîæ‰ΩçÁΩÆË¶ÅÂÜçÈáçÊñ∞Ë®≠Ë®à\n","        text = \"Danger !\"\n","        cv2.putText(img,text, (300, int(border_size-10)), cv2.FONT_HERSHEY_SIMPLEX,0.8,[26,13,247], 2)\n","              #cv2.putText(ÂΩ±ÂÉè, ÊñáÂ≠ó, Â∫ßÊ®ô, Â≠óÂûã, Â§ßÂ∞è, È°èËâ≤, Á∑öÊ¢ùÂØ¨Â∫¶, Á∑öÊ¢ùÁ®ÆÈ°û)\n","    elif 3> lineCount >=1:\n","        text = \"Warning !\"\n","        cv2.putText(img,text, (300, int(border_size-10)), cv2.FONT_HERSHEY_SIMPLEX,0.8,[0,255,255], 2)\n","\n","    else:\n","        text = \"Safe \"\n","        cv2.putText(img,text, (300, int(border_size-10)), cv2.FONT_HERSHEY_SIMPLEX,0.8,[0,255,0], 2)\n","    \n","    #Âè£ÁΩ©ÈÖçÊà¥Ë≠¶Âëä\n","    text=\"mask status         :  \"\n","    cv2.putText(img ,text , (0, int(border_size-50)), cv2.FONT_HERSHEY_SIMPLEX,0.8,border_text_color, 2)\n","    if ratio>=0.1 and nomaskCount>=3: #Á§æ‰∫§Ë∑ùÈõ¢ Ë≠¶Âëä ÔºåÊ¢ù‰ª∂ÂæÖÊîπËâØ ÔºåtextÊì∫Êîæ‰ΩçÁΩÆË¶ÅÂÜçÈáçÊñ∞Ë®≠Ë®à\n","        text = \"Danger !\"\n","        cv2.putText(img,text, (300, int(border_size-50)), cv2.FONT_HERSHEY_SIMPLEX,0.8,[26,13,247], 2)\n","        warning = 'Danger'\n","        \n","    elif ratio!=0 and np.isnan(ratio)!=True: #ratio ‰∏çÂê´Á©∫ÂÄº\n","        text = \"Warning !\"\n","        cv2.putText(img,text, (300, int(border_size-50)), cv2.FONT_HERSHEY_SIMPLEX,0.8,[0,255,255], 2)\n","        warning = 'Warning'\n","\n","    else:\n","        text = \"Safe \"\n","        cv2.putText(img,text, (300, int(border_size-50)), cv2.FONT_HERSHEY_SIMPLEX,0.8,[0,255,0], 2)\n","        warning = 'Safe'\n","    \n","    #Âè£ÁΩ©ÈÖçÊà¥ÊØîÁéá  #Â∞öÊú™ÊúâÊØîÁéáË®àÁÆó\n","    #print(f\"this is ratio: {ratio}\")\n","    text=\"no mask wearing rate  : {}%\".format(ratio)\n","    cv2.putText(img ,text , (0, int(border_size-90)), cv2.FONT_HERSHEY_SIMPLEX,0.8,border_text_color, 2)    \n","    \n","    #Â§öÂ∞ëÊúâÂè£ÁΩ©\n","    text=\"MaskCount: {}\".format(maskCount)\n","    cv2.putText(img ,text , (435, int(border_size-10)), cv2.FONT_HERSHEY_SIMPLEX,0.8,border_text_color, 2) \n","\n","    #Â§öÂ∞ëÊ≤íÈÖçÊà¥Âè£ÁΩ©\n","    text=\"NoMaskCount: {}\".format(nomaskCount)\n","    cv2.putText(img ,text , (435, int(border_size-50)), cv2.FONT_HERSHEY_SIMPLEX,0.8,border_text_color, 2) \n","\n","    #Â§öÂ∞ëÈÅïÂèçÁ§æ‰∫§Ë∑ùÈõ¢ÁöÑÁ¥ÖÁ∑ö #‰πüË®±‰πãÂæå‰∏çÁî® ÂèØ‰ª•Âà™Èô§\n","    # text=\"redLine: {} \".format(lineCount) \n","    # cv2.putText(img ,text , (425, int(border_size-90)), cv2.FONT_HERSHEY_SIMPLEX,0.8,border_text_color, 2)    \n","\n","    \n","    return img, ratio ,warning"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exHvP-oAqc4A"},"source":["def bird_detect_people_on_frame(img, confidence, distance, width, height,border_size, mask_rate_list, mask_warning_list,\n","                                region=None, dst=None):\n","    results = model([img[:, :, ::-1]])  # Pass the frame through the model and get the boxes\n","    \n","    xyxy = results.xyxy[0].cpu().numpy()  # xyxy are the box coordinates\n","    #          x1 (pixels)  y1 (pixels)  x2 (pixels)  y2 (pixels)   confidence        class\n","    # tensor([[7.47613e+02, 4.01168e+01, 1.14978e+03, 7.12016e+02, 8.71210e-01, 0.00000e+00],\n","    #         [1.17464e+02, 1.96875e+02, 1.00145e+03, 7.11802e+02, 8.08795e-01, 0.00000e+00],\n","    #         [4.23969e+02, 4.30401e+02, 5.16833e+02, 7.20000e+02, 7.77376e-01, 2.70000e+01],\n","    #         [9.81310e+02, 3.10712e+02, 1.03111e+03, 4.19273e+02, 2.86850e-01, 2.70000e+01]])\n","\n","    xyxy = xyxy[xyxy[:, 4] >= confidence]  # Filter desired confidence\n","    nomask_xyxy = xyxy[xyxy[:, 5] == 0]\n","    nomask_xyxy = nomask_xyxy[:, :6]\n","\n","    mask_xyxy = xyxy[xyxy[:, 5] == 1] #ÊúâÈÖçÊà¥Âè£ÁΩ© Â∫ßÊ®ô\n","    mask_xyxy = mask_xyxy[:, :6]\n","    \n","    xyxy = xyxy[xyxy[:, 5] == 2]  # Consider only people\n","    xyxy = xyxy[:, :6]\n","    #Ëæ®Ë≠òÂà∞‰∫∫ÁöÑÊñπÊ°ÜÁ∏ΩÊï∏\n","    listclass = xyxy[:,-1].tolist()\n","    toint = [int(i) for i in listclass]\n","    person =toint.count(2)\n","    contactCount = 0\n","    maskCount = 0\n","    nomaskCount = 0\n","\n","    # Calculate the centers of the circles #Ë®àÁÆóÂúìÂøÉ\n","    # They will be the centers of the bottom of the boxes #ÂÆÉÂÄëÂ∞áÊòØÁõíÂ≠êÂ∫ïÈÉ®ÁöÑ‰∏≠ÂøÉ\n","    centers = []\n","    for x1, y1, x2, y2, conf, label in xyxy:\n","        center = [np.mean([x1, x2]), int(y2)+border_size]\n","        #print(f\"this is center: {center}\")\n","        centers.append(center)\n","        # text = \"{}: {:.4f}\".format(model.names[int(label)],conf)  #È°ØÁ§∫ Ëæ®Ë≠ò‰∫∫ÁöÑ name & conf\n","        # img = cv2.putText(img, text, (x1, int(y1)+border_size-5), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 255, 0), 1)  #ÈÄôÈÇäÈ°èËâ≤ÂÖàÈö®‰æø‰∏ä\n","    # We create two transformations\n","    if region is None:\n","        # The region on the original image\n","        region = np.float32([[144, 250], [666, 250], [width, height], [0, height]]) #Á¥ÖÊ°ÜÂçÄÂ°ä ##### ÈáùÂ∞çÂΩ±ÂÉèËß£ÊûêÂ∫¶ ÈÄôÈÇäË¶ÅÈùàÊ¥ªÂÅöË™øÊï¥\n","    if dst is None:\n","        # The rectangle we want the image to be trasnformed to\n","        dst = np.float32([[0, 0], [width, 0], [width, 3*width], [0, 3*width]]) #Êï¥ÂºµÂúñÁâá #ÊäïÂΩ±Âà∞ÁöÑÂçÄÂ°ä #ÈÄôÈÇäÂçÄÂ°äÊåáÊï¥ÂÄãÁï´Èù¢  \n","    # The first transformation is straightforward: the region to the rectangle\n","    # as thin the example before #Á¨¨‰∏ÄÂÄãËΩâÊèõÊòØÁõ¥Êé•Â∞áÂçÄÂüüËΩâÊèõÁÇ∫Áü©ÂΩ¢ÔºåÂ∞±ÂÉè‰πãÂâçÁöÑ‰æãÂ≠ê‰∏ÄÊ®£ËñÑ \n","    M = cv2.getPerspectiveTransform(region, dst)  #Â∞áÂ±ÄÈÉ®ÂçÄÂ°ä Êò†Â∞ÑÂà∞Êï¥ÂÄãÁï´Èù¢\n","\n","    # The second transformation is a trick, because, using the common transformation,\n","    # we can't draw circles at left of the region.\n","    # This way, we flip all things and draw the circle at right of the region,\n","    # because we can do it.\n","    region_flip = region*np.float32([-1, 1]) + np.float32([width, 0]) #Áúã‰∏çÊáÇ Á∏Ω‰πãÊòØÁøªËΩâÂúñÁâá\n","    dst_flip = dst*np.float32([-1, 1]) + np.float32([width, 0])\n","    M_flip = cv2.getPerspectiveTransform(region_flip, dst_flip)\n","\n","    # Convert to bird\n","    # Now, the center of the circles will be positioned on the rectangle\n","    # and we can calculate the usual distance #ÂúìÁöÑ‰∏≠ÂøÉÂ∞á‰ΩçÊñºÁü©ÂΩ¢‰∏äÔºåÊàëÂÄëÂèØ‰ª•Ë®àÁÆóÈÄöÂ∏∏ÁöÑË∑ùÈõ¢ \n","    bird_centers = convert_to_bird(centers, M)  #ÂΩ±Áâá‰∏äÊúâÂπæÂÄã‰∫∫ Â∞±ÊúâÂπæÁµÑ centers\n","\n","    # We verify if the circles colide\n","    # If so, they will be red\n","    colors = ['green']*len(bird_centers)\n","    for i in range(len(bird_centers)): \n","        for j in range(i+1, len(bird_centers)): # 0 1,2,3,4ÊØîË∑ùÈõ¢ 1 2,3,4ÊØîË∑ùÈõ¢\n","            dist = calculate_distance(bird_centers[i], bird_centers[j])\n","            if dist < distance:\n","                #contactCount +=1\n","                colors[i] = 'red'\n","                colors[j] = 'red'\n","\n","    # We draw the circles\n","    # Because we have two transformation, we will start with two empty\n","    # images (\"overlay\" images) to draw the circles\n","    overlay = np.zeros((3*width, 4*width, 3), np.uint8)\n","    overlay_flip = np.zeros((3*width, 4*width, 3), np.uint8)\n","    for i, bird_center in enumerate(bird_centers):\n","        if colors[i] == 'green':\n","            color = (0, 255, 0)\n","        else:\n","            color = (0, 0, 255)\n","            contactCount +=1\n","        x, y = bird_center\n","        x = int(x)\n","        y = int(y)\n","        if x >= int(distance/2+15/2): #ÈÄôÁîöÈ∫ºÁ•ûÂ•áÁÆóÂºè #Â∞±ÊòØÁï´ÂúìÂúàÂ∞±Â∞ç‰∫Ü\n","            # If it's the case the circle is inside or at right of our region\n","            # we can use the normal overlay image\n","            overlay = cv2.circle(overlay, (x, y), int(distance/2),\n","                                  color, 15, lineType=cv2.LINE_AA)\n","        else:\n","            # If the circle is at left of the region,\n","            # we draw the circle inverted on the other overlay image\n","            x = width - x\n","            overlay_flip = cv2.circle(overlay_flip, (x, y), int(distance/2),\n","                                  color, 15, lineType=cv2.LINE_AA)\n","\n","    # We apply the inverse transformation to the overlay\n","    overlay = cv2.warpPerspective(overlay, M, (width, height),\n","                                  cv2.INTER_NEAREST, cv2.WARP_INVERSE_MAP) #ÊääÂúñÂÉè Êò†Â∞ÑÂà∞Êï¥ÂÄãframe\n","    # We apply the inverse of the other transformation to the other overlay\n","    overlay_flip = cv2.warpPerspective(overlay_flip, M_flip, (width, height),\n","                                       cv2.INTER_NEAREST, cv2.WARP_INVERSE_MAP)\n","    # Now we \"unflip\" what the second overlay\n","    overlay_flip = cv2.flip(overlay_flip, 1)\n","\n","    # Â¢ûÂä†ÈÇäÊ°Ü\n","    img = cv2.copyMakeBorder(img, border_size,0,0,0, cv2.BORDER_CONSTANT)\n","\n","    #ÊúâÈÖçÊà¥Âè£ÁΩ© Â∫ßÊ®ô\n","    for i, (x1, y1, x2, y2, c1, label) in enumerate(mask_xyxy):\n","        # Draw the boxes   \n","        #print(f\"this is i: {i}\")\n","        #if mask_colors[i] == 'green':\n","        mask_colors = (0, 255, 0)#Á∂†\n","        maskCount += 1\n","        #else:\n","        #    mask_colors = (0, 0, 255)          \n","        img = cv2.rectangle(img, (int(x1), int(y1)+border_size), (int(x2), int(y2)+border_size), mask_colors, 2) #‰πãÂæåÂÜçÁúãÊúâÊ≤íÊúâËÅ∞Êòé‰∏ÄÈªûÊñπÂºèËΩâÊàêint\n","        \n","        text = \"{}: {:.4f}\".format(model.names[int(label)],c1)\n","        img = cv2.putText(img, text, (int(x1), int(y1)+border_size-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, mask_colors, 2)\n","    \n","    #ÁÑ°ÈÖçÊà¥Âè£ÁΩ© Â∫ßÊ®ô\n","    for i, (x1, y1, x2, y2, c1, label) in enumerate(nomask_xyxy):\n","        # Draw the boxes   \n","        mask_colors = (0, 0, 255)#Á¥Ö\n","        nomaskCount += 1\n","        img = cv2.rectangle(img, (int(x1), int(y1)+border_size), (int(x2), int(y2)+border_size), mask_colors, 2) #‰πãÂæåÂÜçÁúãÊúâÊ≤íÊúâËÅ∞Êòé‰∏ÄÈªûÊñπÂºèËΩâÊàêint\n","        \n","        text = \"{}: {:.4f}\".format(model.names[int(label)],c1)\n","        img = cv2.putText(img, text, (int(x1), int(y1)+border_size-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, mask_colors, 2) \n","            #cv2.putText(ÂΩ±ÂÉè, ÊñáÂ≠ó, Â∫ßÊ®ô, Â≠óÂûã, Â§ßÂ∞è, È°èËâ≤, Á∑öÊ¢ùÂØ¨Â∫¶, Á∑öÊ¢ùÁ®ÆÈ°û)\n","    # textÂ¢ûÂä†\n","    img_text(img, border_size, person, contactCount, maskCount, nomaskCount)[0]\n","    \n","    mask_rate_list.append(img_text(img, border_size, person, contactCount, maskCount, nomaskCount)[1])\n","    mask_warning_list.append(img_text(img, border_size, person, contactCount, maskCount, nomaskCount)[2])\n","    # We add all images\n","    img = cv2.addWeighted(img, 1, overlay, 1, 0)\n","    img = cv2.addWeighted(img, 1, overlay_flip, 1, 0)\n","    \n","\n","    return img, mask_rate_list, mask_warning_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSvGGFm8u8oO","executionInfo":{"elapsed":531,"status":"ok","timestamp":1626102246030,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"},"user_tz":-480},"outputId":"79646f3b-8057-424d-d467-fe91614e8ada"},"source":["a = ['bang','bang','apple','ggwp','ggwp']\n","rep = [0 if x =='bang' else x for x in a]\n","rep = [1 if x =='ggwp' else x for x in rep]\n","rep = [2 if x =='apple' else x for x in rep]\n","# Danger= 2 Ôºåwarning= 1 , Safe= 0\n","rep"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 2, 1, 1]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"YswQEJ9ZcrA4"},"source":["def mask_rate_line_plot(mask_rate_list, frameCount):\n","  #ÊäòÁ∑öÂúñ #Ëº∏Âá∫ÂñÆÂºµÂúñ\n","  fig = plt.figure()\n","  frame = range(1,frameCount+1)\n","  plt.plot(frame, mask_rate_list, color = 'blue')\n","  plt.xlabel('frame')\n","  plt.ylabel('rate')\n","  plt.ylim(0, 101)\n","  plt.title('mask rate')\n","  fig.set_figheight(3)\n","  fig.set_figwidth(10)\n","  plt.savefig('mask_rate_line_plot.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DF2iRJEIwMJc"},"source":["def mask_rate_scatter_plot(mask_rate_list, frameCount):\n","  #Êï£ÈªûÂúñ #Ëº∏Âá∫ÂñÆÂºµÂúñ\n","  fig = plt.figure()     \n","  frame = range(1,frameCount+1)\n","  plt.scatter(frame, mask_rate_list, c=\"red\")\n","  plt.xlabel(\"frame\")\n","  plt.ylabel(\"rate\")\n","  plt.ylim(0, 101)\n","  plt.title(\"mask rate\")\n","  fig.set_figheight(4)\n","  fig.set_figwidth(8)\n","  plt.savefig('mask_rate_scatter_plot.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASW7s_4OaE_O"},"source":["def mask_warning_line_plot(mask_warning_list_int, frameCount):\n","  #ÊäòÁ∑öÂúñ\n","  my_yticks = ['Safe','Warning','Danger']\n","  fig = plt.figure()\n","  frame = range(1,frameCount+1)\n","  plt.plot(frame, mask_warning_list_int, color = 'blue')\n","  plt.xlabel('frame')\n","  plt.ylabel('warning')\n","  #plt.ylim(0, 2)\n","  plt.yticks([0,1,2], my_yticks)\n","  plt.margins(0.08) #YËª∏ Âè™Ê∂µËìãÂà∞ÊúâÁöÑ Â¶ÇÊûúlistÂè™ÊúâwarningÂíåsafe YËª∏‰∏çÊúÉÂá∫Áèædanger\n","            #‰∏¶‰∏îËÆìsafeËàáÂ∫ïÈÉ®Áõ∏Â∑Æ0.08\n","  plt.subplots_adjust(bottom=0.15) #ÊîπËÆäÂ≠êÂúñÈñìË∑ù  \n","  plt.title('mask rate')\n","  fig.set_figheight(3)\n","  fig.set_figwidth(10)\n","  plt.savefig('mask_warning_line_plot.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FxETAknepVb","executionInfo":{"elapsed":11,"status":"ok","timestamp":1625794098526,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"},"user_tz":-480},"outputId":"5aed3d75-4e43-4a8d-c5d1-469c1db3d573"},"source":["a = [2,2,2,2,2,3,3,3,3,1,1,1,1,1]\n","b = a.count(2)\n","c = a.count(3)\n","d = a.count(1)\n","e = [b,c,d]\n","e"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[5, 4, 5]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"-4vZZo5e1JEX"},"source":["def mask_rate(mask_rate_list, frameCount):\n","  #ÊäòÁ∑öÂúñ ax1  #‰∏çÁü•ÈÅìÊ®ôÈ°åË¶Å‰∏çË¶ÅÂ¢ûÂä†Ë™™Êòé #ÊªëÂãïÂπ≥ÂùáÊøæÊ≥¢\n","  #Êï£ÈªûÂúñ ax2\n","  conv_list = np.array(mask_rate_list)\n","  w = 10\n","  conv_list = np.convolve(conv_list, np.ones(w), 'valid') / w #ÊªëÂãïÂπ≥ÂùáÊøæÊ≥¢\n","  conv_list = list(conv_list)\n","  print(f\"this is framecount before: {frameCount}\")\n","  orgin_frameCount = frameCount\n","  frameCount = len(conv_list)\n","  print(f\"this is framecount after: {frameCount}\")\n","  fig,(ax1, ax2) = plt.subplots(2)\n","\n","  frame = range(1,frameCount+1)\n","  orgin_frameCount = range(1,orgin_frameCount+1)\n","  ax1.plot(frame, conv_list, color = 'blue')\n","  ax2.scatter(orgin_frameCount, mask_rate_list, c=\"blue\")\n","  \n","  ax1.set_title(\"no mask rate line plot\",fontsize= 25, fontweight='medium')\n","  ax2.set_title(\"no mask rate scatter plot\",fontsize= 25, fontweight='medium')\n","  \n","  ax1.set_xlabel(\"frame\",fontsize=15)\n","  ax1.set_ylabel(\"rate\",fontsize=15)\n","  #ax1.set_ylim(0, 101) #ÊúÉËìãÈÅé marginsÊïàÊûú\n","  ax1.set_yticks([0,10,20,30,40,50,60,70,80,90,100]) #Ëá™Ë®ÇyËª∏\n","  ax1.margins(0.08)\n","  ax1.grid(color='r', linestyle='dotted', linewidth=1) #‰πãÂæåÂïèÂà•‰∫∫ÊÑèË¶ãÊòØÂê¶ÊúâË¶ÅÊ†ºÁ∑ö\n","\n","  ax2.set_xlabel(\"frame\",fontsize=15)\n","  ax2.set_ylabel(\"rate\",fontsize=15)\n","  #ax2.set_ylim(0, 101)\n","  ax2.set_yticks([0,10,20,30,40,50,60,70,80,90,100])\n","  ax2.margins(0.08)\n","  ax2.grid(color='r', linestyle='dotted', linewidth=1)\n","\n","  fig.set_figheight(8) #ÂÖ©ÂºµÂúñ‰∏ÄËµ∑ÊîπËÆä\n","  fig.set_figwidth(10)\n","  fig.tight_layout() #tight_layout() ÊñπÊ≥ïÊõ¥Êîπ Matplotlib Â≠êÂúñÂ§ßÂ∞èÂíåÈñìË∑ù(ÈÅøÂÖç‰∏ä‰∏ãÈáçÁñä\n","\n","  plt.savefig('mask_rate.png')\n","  #plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-PN-JqqhuMg","executionInfo":{"elapsed":260,"status":"ok","timestamp":1625737867862,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"},"user_tz":-480},"outputId":"ad313a80-0cb9-48b3-f0e0-12cd713bc38b"},"source":["np.arange(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"VPu1_Nz4cK4j"},"source":["def mask_warning(mask_warning_list_int, frameCount):\n","  #ÊäòÁ∑öÂúñ ax1  #‰∏çÁü•ÈÅìÊ®ôÈ°åË¶Å‰∏çË¶ÅÂ¢ûÂä†Ë™™Êòé\n","  #Èï∑Ê¢ùÂúñ ax2\n","  safe = mask_warning_list_int.count(0)\n","  #print(f\"this is safe count: {safe}\")\n","  warning = mask_warning_list_int.count(1)\n","  #print(f\"this is warning count: {warning}\")\n","  danger = mask_warning_list_int.count(2)\n","  warning_count = [safe,warning,danger]\n","\n","  fig,(ax1, ax2) = plt.subplots(2)\n","  frame = range(1,frameCount+1)\n","  my_ticks = ['Safe','Warning','Danger']\n","  x = np.arange(len(my_ticks))\n","\n","  ax1.plot(frame, mask_warning_list_int, color = 'blue')\n","  ax2.bar(x, warning_count, color=['red', 'green', 'blue'])\n","  \n","  ax1.set_title(\"mask warning line plot\",fontsize= 25, fontweight='medium')\n","  ax2.set_title(\"mask warning bar charts\",fontsize= 25, fontweight='medium')\n","\n","  ax1.set_xlabel(\"frame\",fontsize=15)\n","  ax1.set_ylabel(\"rate\",fontsize=15)\n","  ax1.set_yticks([0,1,2])\n","  ax1.set_yticklabels(my_ticks)\n","  ax1.margins(0.08) #YËª∏ Âè™Ê∂µËìãÂà∞ÊúâÁöÑ Â¶ÇÊûúlistÂè™ÊúâwarningÂíåsafe YËª∏‰∏çÊúÉÂá∫Áèædanger\n","            #‰∏¶‰∏îËÆìsafeËàáÂ∫ïÈÉ®Áõ∏Â∑Æ0.08\n","  for a,b in zip(x, warning_count):\n","    ax2.text(a, b+0.05, '%.0f' % b, ha='center', va= 'bottom',fontsize=11) #Â¢ûÂä†bar‰∏äÈ°ØÁ§∫Êï∏Â≠ó\n","\n","  ax2.set_xticks([0,1,2])\n","  ax2.set_xticklabels(my_ticks)\n","  ax2.set_xlabel(\"warning\",fontsize=15) #Ë¶Å‰∏çË¶ÅÊîπÂ§ßÂØ´?\n","  ax2.set_ylabel(\"count\",fontsize=15)\n","\n","  fig.set_figheight(9) #ÂÖ©ÂºµÂúñ‰∏ÄËµ∑ÊîπËÆä\n","  fig.set_figwidth(10)\n","  fig.tight_layout() #tight_layout() ÊñπÊ≥ïÊõ¥Êîπ Matplotlib Â≠êÂúñÂ§ßÂ∞èÂíåÈñìË∑ù(ÈÅøÂÖç‰∏ä‰∏ãÈáçÁñä\n","\n","  plt.savefig('mask_warning.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NagNkF9Uqc7X"},"source":["def bird_detect_people_on_video(filename, confidence=0.9, distance=160):\n","    # Capture video\n","    cap = cv2.VideoCapture(filename)\n","\n","    border_size=125\n","\n","    mask_rate_list = []\n","    mask_warning_list = []\n","    frameCount = 0\n","    # Get video properties\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) +border_size\n","\n","    # Define the codec and create VideoWriter object\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    if os.path.exists('bird_output.avi'):\n","        os.remove('bird_output.avi')\n","    out = cv2.VideoWriter('bird_output.avi', fourcc, fps, (width, height))\n","\n","    # Iterate through frames\n","    vidlen = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    with tqdm(total=vidlen) as pbar:\n","        while cap.isOpened():\n","            # Read frame\n","            ret, frame = cap.read()\n","            if ret == True:\n","                # Detect people as a bird\n","                frame = bird_detect_people_on_frame(frame, confidence, distance,\n","                                                    width, height, border_size, mask_rate_list, mask_warning_list)[0]\n","                #print(f\"mask_rate_list len :{len(mask_rate_list)}\")\n","                frameCount += 1\n","                # Write frame to new video\n","                out.write(frame)\n","                pbar.update(1)\n","            else:\n","                break\n","\n","    # print(f\"count: {frameCount}\")\n","\n","    # Danger= 2 Ôºåwarning= 1 , Safe= 0\n","    mask_warning_list_int = [0 if x =='Safe' else x for x in mask_warning_list]\n","    mask_warning_list_int = [1 if x =='Warning' else x for x in mask_warning_list_int]\n","    mask_warning_list_int = [2 if x =='Danger' else x for x in mask_warning_list_int]\n","    # print(f\"mask_warning_list_int len :{len(mask_warning_list_int)}\")\n","    # print(f\"mask_warning_list_int: {(mask_warning_list_int)}\")\n","    \n","    # line plot\n","    #mask_warning_line_plot(mask_warning_list_int, frameCount)\n","    mask_warning(mask_warning_list_int, frameCount)\n","    # # line plot\n","    # mask_rate_line_plot(mask_rate_list, frameCount)\n","    # # scatter plot\n","    # mask_rate_scatter_plot(mask_rate_list, frameCount)\n","    #Ëº∏Âá∫ line plot + scatter plot\n","    mask_rate(mask_rate_list, frameCount)\n","    # Release everything if job is finished\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()\n","\n","    #return mask_rate_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154,"referenced_widgets":["947619ba3e9642a289092a3f8f417d21","0f99d49c07cd4c84b29ca4afdc59dd09","1eb1879a1f5b451394909da7c18f2272","c3893d230ba14e31a123c322495bc1eb","a64b441fafea4c318b02e1dffbe57340","f67a8064abdb4a3ca2ae04381dc91f65","365f652352044a21b9a00b54ff03bd5a","37bebf65b1a943e2a0ff361925b1af5f"]},"id":"l2U_mOn8qc_D","executionInfo":{"status":"ok","timestamp":1626321253420,"user_tz":-480,"elapsed":34498,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"}},"outputId":"2cd564d6-5ff6-44fc-8b07-93a6f1f4d33d"},"source":["bird_detect_people_on_video(filename, confidence=0.5, distance=200)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"947619ba3e9642a289092a3f8f417d21","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=349.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","this is framecount before: 349\n","this is framecount after: 340\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298,"output_embedded_package_id":"1hrT9sg7AE39MWqx-1y18dgREYii7z9TO"},"id":"MOih31VXqdCZ","executionInfo":{"status":"ok","timestamp":1626321277460,"user_tz":-480,"elapsed":23781,"user":{"displayName":"ki ao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjzs6JVnmMMvQM356EDCFEmMZxcvdxAdS2yJOoS=s64","userId":"12804173535351020533"}},"outputId":"b0edd895-e5ce-4374-f590-09114a8011e6"},"source":["display_video('bird_output.avi')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"WeOA2ui9qdGB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATcDf39nqdJV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4y0v-N9qdMp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KykKHVPYqdPq"},"source":[""],"execution_count":null,"outputs":[]}]}